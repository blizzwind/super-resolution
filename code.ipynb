{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a41800",
   "metadata": {},
   "source": [
    "### pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd648183",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "for i in os.listdir(\"raw\"):\n",
    "    img = tifffile.imread(\"raw/\"+i)\n",
    "    h = img.shape[0]/4\n",
    "    w = img.shape[1]/4\n",
    "    img = img[int(h):int(3*h),int(w):int(3*w)]\n",
    "    for j in range(img.shape[0]//128):\n",
    "        for k in range(img.shape[1]//128):\n",
    "            tif = img[j*128:(j+1)*128,k*128:(k+1)*128]\n",
    "            tifffile.imwrite(\"input/hr/\"+str(t)+\".tif\",tif)\n",
    "            r = random.randint(1,5)\n",
    "            if r == 1:\n",
    "                tif = cv2.resize(tif, dsize=(32,32), interpolation=cv2.INTER_NEAREST)\n",
    "            elif r == 2:\n",
    "                tif = cv2.resize(tif, dsize=(32,32), interpolation=cv2.INTER_LINEAR)\n",
    "            elif r == 3:\n",
    "                tif = cv2.resize(tif, dsize=(32,32), interpolation=cv2.INTER_AREA)\n",
    "            elif r == 4:\n",
    "                tif = cv2.resize(tif, dsize=(32,32), interpolation=cv2.INTER_CUBIC)\n",
    "            else:\n",
    "                tif = cv2.resize(tif, dsize=(32,32), interpolation=cv2.INTER_LANCZOS4)\n",
    "            tifffile.imwrite(\"input/lr/\"+str(t)+\".tif\",tif)\n",
    "            t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e657e",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee82edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(os.listdir(\"input/hr\"))\n",
    "l = os.listdir(\"input/hr\")\n",
    "hr = np.full((num,128,128,1),np.nan)\n",
    "for i in tqdm(range(num)):\n",
    "    img = tifffile.imread(\"input/hr/\"+l[i])\n",
    "    img = (img-img.min())/(img.max()-img.min())\n",
    "    hr[i,:,:,0] = img\n",
    "num = len(os.listdir(\"input/hr\"))\n",
    "l = os.listdir(\"input/lr\")\n",
    "lr = np.full((num,32,32,1),np.nan)\n",
    "for i in tqdm(range(num)):\n",
    "    img = tifffile.imread(\"input/lr/\"+l[i])\n",
    "    img = (img-img.min())/(img.max()-img.min())\n",
    "    lr[i,:,:,0] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((lr,hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba162883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block_gen(ch=64,k_s=3,st=1):\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(ch,k_s,strides=(st,st),padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Conv2D(ch,k_s,strides=(st,st),padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def Upsample_block(x, ch=256, k_s=3, st=1):\n",
    "    x = tf.keras.layers.Conv2D(ch,k_s, strides=(st,st),padding=\"same\")(x)\n",
    "    x = tf.nn.depth_to_space(x, 2)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    return x\n",
    "\n",
    "input_lr=tf.keras.layers.Input(shape=(None,None,1))\n",
    "input_conv=tf.keras.layers.Conv2D(64,9,padding=\"same\")(input_lr)\n",
    "input_conv=tf.keras.layers.LeakyReLU()(input_conv)\n",
    "SRRes=input_conv\n",
    "for x in range(5):\n",
    "    res_output=residual_block_gen()(SRRes)\n",
    "    SRRes=tf.keras.layers.Add()([SRRes,res_output])\n",
    "SRRes=tf.keras.layers.Conv2D(64,9,padding=\"same\")(SRRes)\n",
    "SRRes=tf.keras.layers.BatchNormalization()(SRRes)\n",
    "SRRes=tf.keras.layers.Add()([SRRes,input_conv])\n",
    "SRRes=Upsample_block(SRRes)\n",
    "SRRes=Upsample_block(SRRes)\n",
    "output_sr=tf.keras.layers.Conv2D(1,9,activation=\"tanh\",padding=\"same\")(SRRes)\n",
    "SRResnet=tf.keras.models.Model(input_lr,output_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3dcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block_disc(ch=64,k_s=3,st=1):\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(ch,k_s,strides=(st,st),padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "input_lr=tf.keras.layers.Input(shape=(128,128,1))\n",
    "input_conv=tf.keras.layers.Conv2D(64,1,padding=\"same\")(input_lr)\n",
    "input_conv=tf.keras.layers.LeakyReLU()(input_conv)\n",
    "channel_nums=[64,128,128,256,256,512,512]\n",
    "stride_sizes=[2,1,2,1,2,1,2]\n",
    "disc=input_conv\n",
    "for x in range(7):\n",
    "    disc=residual_block_disc(ch=channel_nums[x],st=stride_sizes[x])(disc)\n",
    "disc=tf.keras.layers.Flatten()(disc)\n",
    "disc=tf.keras.layers.Dense(1024)(disc)\n",
    "disc=tf.keras.layers.LeakyReLU()(disc)\n",
    "disc_output=tf.keras.layers.Dense(1,activation=\"sigmoid\")(disc)\n",
    "discriminator=tf.keras.models.Model(input_lr,disc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(y_true,y_pred):\n",
    "    y_pred = tf.cast(y_pred,tf.float64)\n",
    "    mse=tf.reduce_mean( (y_true - y_pred) ** 2 )\n",
    "    return 20 * log10(1 / (mse ** 0.5))\n",
    "\n",
    "def log10(x):\n",
    "    numerator = tf.math.log(x)\n",
    "    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "def pixel_MSE(y_true,y_pred):\n",
    "    y_pred = tf.cast(y_pred,tf.float64)\n",
    "    return tf.reduce_mean( (y_true - y_pred) ** 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c749b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(data,loss_func=pixel_MSE,adv_learning=True,evaluate=[\"PSNR\"],adv_ratio=0.001):\n",
    "    logs={}\n",
    "    gen_loss,disc_loss=0,0\n",
    "    low_resolution,high_resolution=data\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        super_resolution = SRResnet(low_resolution, training=True)\n",
    "        gen_loss=loss_func(high_resolution,super_resolution)\n",
    "        logs[\"reconstruction\"]=gen_loss\n",
    "        if adv_learning:\n",
    "            real_output = discriminator(high_resolution, training=True)\n",
    "            fake_output = discriminator(super_resolution, training=True)\n",
    "            adv_loss_g = generator_loss(fake_output) * adv_ratio\n",
    "            gen_loss += adv_loss_g\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "            logs[\"adv_g\"]=adv_loss_g\n",
    "            logs[\"adv_d\"]=disc_loss\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, SRResnet.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, SRResnet.trainable_variables))\n",
    "    if adv_learning:\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    for x in evaluate:\n",
    "        if x==\"PSNR\":\n",
    "            logs[x]=PSNR(high_resolution,super_resolution)\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer=tf.keras.optimizers.Adam(0.001)\n",
    "discriminator_optimizer=tf.keras.optimizers.Adam(0.001)\n",
    "adv_ratio=0.001\n",
    "evaluate=[\"PSNR\"]\n",
    "loss_func,adv_learning = pixel_MSE,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(500):\n",
    "    print(\"epoch:\",x)\n",
    "    for image_batch in tqdm(data.batch(32), position=0, leave=True):\n",
    "        logs=train_step(image_batch,loss_func,adv_learning,evaluate,adv_ratio)\n",
    "    print(\"reconstruction:\",logs[\"reconstruction\"],\"  PSNR:\",logs[\"PSNR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a215bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRResnet.save(\"output/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3e427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
